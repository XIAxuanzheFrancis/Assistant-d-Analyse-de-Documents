**Assistant_d'Analyse_de_Documents_2.1-2.3.ipynb** completes 2.1-2.3, avec un plateforme colab

**Assistant_d'Analyse_de_Documents.ipynb** completes 2.1-2.3, experimental environment python 3.11 (tools vs code) [spÃ©cifie explicitement les tokens, impose l'utilisation de SentencePiece et Ã©vite les erreurs de conversion tiktoken].

2.4 Interface utilisateur

DÃ©velopper une interface web Ã  l'aide d'un framework tel que Streamlit et permettez aux utilisateurs de tÃ©lÃ©charger des fichiers, de poser des questions et d'interagir avec l'assistant. Voici l'implÃ©mentation dans app.py. AprÃ¨s la prÃ©cÃ©dente transformation du code, answer_question utilisait Camembert pour les questions-rÃ©ponses, mais les phrases de rÃ©ponse Ã©taient trop courtes et pas assez prÃ©cises. J'ai donc utilisÃ© le modÃ¨le mistral de Hugging Face, augmentÃ© la longueur des rÃ©ponses et essayÃ© plusieurs sÃ©ries de rÃ©ponses.

![img](./ressources/plateform_res.jpg)

Assistant d'Analyse de Documents

3 Extensions optionnelles
**- Support multilingue : permettre lâ€™extraction de texte et la rÃ©ponse aux questions dans plusieurs langues.**

J'utilise la bibliothÃ¨que langdetect pour dÃ©tecter la langue des documents tÃ©lÃ©chargÃ©s. En fonction de la langue dÃ©tectÃ©e (franÃ§ais ou anglais), le modÃ¨le correspondant sera chargÃ© (etalab-ia/camembert-base-squadFR-fquad-piaf pour le franÃ§ais, distilbert-base-uncased-distilled-squad pour l'anglais).
Cela permet Ã  l'utilisateur d'extraire du texte et de poser des questions dans plusieurs langues. Si le document est en franÃ§ais, le modÃ¨le franÃ§ais est utilisÃ© ; s'il est en anglais, le modÃ¨le anglais est utilisÃ©.
![img](./ressources/Support%20multilingue.jpg)

**- IntÃ©gration vocale : permettre aux utilisateurs dâ€™interagir avec lâ€™assistant via des commandes vocales.**

La fonction record_audio() permet la saisie vocale. Lorsque l'utilisateur clique sur le bouton Â« ğŸ¤ Poser une question par voix Â», le systÃ¨me Ã©coute la question de l'utilisateur Ã  l'aide du microphone et la traite Ã  l'aide de l'API de conversion de la parole en texte de Google (recognize_google), ce qui permet une interaction vocale avec l'assistant.

Les utilisateurs disposent ainsi d'un moyen intuitif d'interagir avec l'assistant sans avoir Ã  taper au clavier.

![img](./ressources/IntÃ©gration%20vocale.jpg)

**- MÃ©canisme de feedback : implÃ©menter un systÃ¨me de retour utilisateur pour affiner les rÃ©ponses de lâ€™assistant au fil du temps.**

AprÃ¨s avoir fourni une rÃ©ponse, les utilisateurs sont invitÃ©s Ã  rÃ©agir en demandant s'ils ont trouvÃ© la rÃ©ponse utile (Â« Avez-vous trouvÃ© la rÃ©ponse utile ? Â»).

S'il sÃ©lectionne Â« Non Â», il peut fournir des commentaires supplÃ©mentaires sur la maniÃ¨re dont la rÃ©ponse peut Ãªtre amÃ©liorÃ©e. Ces commentaires sont stockÃ©s dans un fichier texte (feedback.txt), ce qui permet d'affiner les rÃ©ponses au fil du temps.

![img](./ressources/MÃ©canisme%20de%20feedback1.jpg)
![img](./ressources/MÃ©canisme%20de%20feedback2.jpg)
![img](./ressources/MÃ©canisme%20de%20feedback3.jpg)
![img](./ressources/MÃ©canisme%20de%20feedback4.jpg)
